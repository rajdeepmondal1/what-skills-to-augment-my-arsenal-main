{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Skills to augment to my arsenal",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPCbbQOX3jASkucVOp7OokY"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Using Intelligence from Indeed Job postings to augment my skills."
      ],
      "metadata": {
        "id": "v7v6tYlKuNTl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Problem statement\n",
        "I am confused on what skills are most relevant in the current job market. So after learning Ensemble learning, I loved the concept and thought of applying that idea to find my skills gap using ensemble of relevant skill data from the Indeed job posting. More like an wisdom of crowd approach. So I am aiming to find relevant skills that I should learn next before applying for my next Job to improve my odds of getting hired, and feel more confident."
      ],
      "metadata": {
        "id": "jx08KnRou6wO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Approach\n",
        "First we will download data from Indeed. I made a web scraper https://github.com/rajdeepmondal1/indeed-job-scraper that scrapes the https://in.indeed.com/ website for our essential data after searching for Data Scientist, Data Engineer, Data Science Consultant, Data Analyst and Machine Learning Engineer. Since the lines are blurry about what a Data Scientist does, we scrape data about these adjacent titles to remove bias in our data. Indeed website offers millions of searchable job listings, posted by understaffed employers. It has a built-in search engine, which allows us to filter the jobs by keyword. We will download the required information and store it in separate html files for the job listings.\n",
        "\n",
        "Our goal is to extract common data science and machine learning skills from the downloaded data. We’ll then compare these skills to our skills to determine which skills are missing. To reach our goal, we’ll proceed like this:\n",
        " - Parse out all the text from the downloaded HTML files.\n",
        " - Explore the parsed output to learn how job skills are commonly described in online postings. Perhaps specific HTML tags are more commonly used to underscore job skills.\n",
        " - Try to filter out any irrelevant job postings from our dataset. The search engine isn’t perfect. Perhaps some irrelevant postings were erroneously downloaded. We can evaluate relevance by comparing the postings with our skill list.\n",
        " - Cluster the job skills within the relevant postings, and visualize the clusters.\n",
        " - Make a plan to improve on the skills that are missing."
      ],
      "metadata": {
        "id": "13K5X5JAwj5b"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "Gq-YWC2nd_md"
      },
      "outputs": [],
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/rajdeepmondal1/what-skills-to-augment-my-arsenal-main"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GFBt6b3TtKNK",
        "outputId": "9c6e72dd-f738-4cd2-a160-09af862f99ea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'what-skills-to-augment-my-arsenal-main'...\n",
            "remote: Enumerating objects: 10, done.\u001b[K\n",
            "remote: Counting objects: 100% (10/10), done.\u001b[K\n",
            "remote: Compressing objects: 100% (10/10), done.\u001b[K\n",
            "remote: Total 10 (delta 1), reused 6 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (10/10), done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_location = '/content/what-skills-to-augment-my-arsenal-main/data/data_2161_listings.zip'"
      ],
      "metadata": {
        "id": "9iibCDGDtSm6"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unzip_data(data_location)"
      ],
      "metadata": {
        "id": "qD5xqgz9tZ6Y"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Dataset description\n",
        "I have scraped a total of 2161 listings using https://github.com/rajdeepmondal1/indeed-job-scraper from https://in.indeed.com/ including -\n",
        " - Data Scientist with 735 listings\n",
        " - Machine Learning Engineer with 654 listings\n",
        " - Data Engineer with 317 listings\n",
        " - Data Science Consultant with 151 listings\n",
        " - Data Analyst with 304 listings\n",
        "The title, company name, ratings and job description was scraped from the website for each listing.\n",
        "\n",
        "Our rough draft of skills are stored in the skills.txt file."
      ],
      "metadata": {
        "id": "jpWlV2d3xU1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "We will proceed as follows:\n",
        "\n",
        "1. Parse all text from the downloaded HTML files.\n",
        "2. Explore the parsed output to learn how job skills are described in online postings. We’ll pay particular attention to whether certain HTML tags are more associated with skill descriptions.\n",
        "3. Attempt to filter any irrelevant job postings from our dataset.\n",
        "4. Cluster job skills based on text similarity.\n",
        "5. Visualize the clusters using word clouds.\n",
        "6. Adjust clustering parameters, if necessary, to improve the visualized output.\n",
        "7. Compare the clustered skills to our resume to uncover missing skills."
      ],
      "metadata": {
        "id": "JpJRsQCnx8_D"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Extracting skill requirements from job posting data"
      ],
      "metadata": {
        "id": "vEPTa2vXyRjE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1. Loading HTML files"
      ],
      "metadata": {
        "id": "-tGbnYczyVep"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "\n",
        "# Evading any warnings\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "vVI_NSMCyb1n"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "html_contents = []\n",
        "\n",
        "for file_name in sorted(glob.glob('/content/data_2161_listings/*/*.html')):\n",
        "    with open(file_name, encoding=\"utf8\") as f:\n",
        "        html_contents.append(f.read())\n",
        "        \n",
        "print(f\"We've loaded {len(html_contents)} HTML files.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "60Ll0C5Gtcya",
        "outputId": "578bd888-596a-4b6c-b4b9-ee87d86aeeaf"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We've loaded 2161 HTML files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "0UNYZb3DynmC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}